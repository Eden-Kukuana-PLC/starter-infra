controller:
  replicas: 1
  type: 'deployment'

alloy:
  extraPorts:
    - name: grpc-otel
      port: 4317         # OpenTelemetry gRPC port
      targetPort: 4317
    - name: otlp-http
      port: 4318         # OpenTelemetry HTTP port
      targetPort: 4318
  mounts:
    varlog: true
  configMap:
    content: |
      logging {
        level  = "debug"
        format = "logfmt"
      }

      discovery.kubernetes "pods" {
        role = "pod"
      }

      loki.source.kubernetes "pods" {
        targets    = discovery.kubernetes.pods.targets
        forward_to = [loki.write.endpoint.receiver]
      }
      
      otelcol.processor.batch "default" {
      
        send_batch_size = 10
        send_batch_max_size = 20
        // Or until 2 seconds have elapsed.
        timeout = "2s"
      
        output {
          logs = [otelcol.exporter.otlphttp.loki.input]
          traces = [otelcol.exporter.otlp.tempo.input]
          metrics = [otelcol.exporter.prometheus.tracemetrics.input]
        }
      }
      
      otelcol.receiver.otlp "otel_receiver" {
        http {}
        grpc {}
      
        output {
          logs    = [otelcol.processor.batch.default.input]
          traces = [otelcol.processor.batch.default.input, otelcol.connector.spanmetrics.tracemetrics.input]
          metrics = [otelcol.processor.batch.default.input]
        }
      }
      
      otelcol.exporter.otlphttp "loki" {
        client {
          endpoint = "http://loki-gateway.monitoring.svc.cluster.local:80/otlp"
        }
      }

      loki.write "endpoint" {
        endpoint {
            url = "http://loki-gateway.monitoring.svc.cluster.local:80/loki/api/v1/push"
            tenant_id = "local"
        }
      }
      
      // The OpenTelemetry exporter exports processed trace spans to another target that is listening for OTLP format traces.
      // A unique label, 'tempo', is added to uniquely identify this exporter.
      otelcol.exporter.otlp "tempo" {
          // Define the client for exporting.
          client {

              // Send to the locally running Tempo instance, on port 4317 (OTLP gRPC).
              endpoint = "http://tempo.monitoring.svc.cluster.local:4317"
      
              tls {
                  insecure = true
                  insecure_skip_verify = true
              }

          }
      }
      
      // The OpenTelemetry Prometheus exporter will transform incoming OTLP metrics data into Prometheus format data.
      otelcol.exporter.prometheus "tracemetrics" {
        // Forward to our local Prometheus remote writer which will send the metrics to Mimir.
        forward_to = [prometheus.remote_write.mimir.receiver]
      }
      
      prometheus.remote_write "mimir" {
          // The endpoint is the Mimir service.
          endpoint {
            url = "http://mimir-nginx.monitoring.svc.cluster.local:80/api/v1/push"
          }
      }
      
      // The Spanmetrics Connector will generate RED metrics based on the incoming trace span data.
      otelcol.connector.spanmetrics "tracemetrics" {
        // The namespace explicit adds a prefix to all the generated span metrics names.
        // In this case, we'll ensure they match as closely as possible those generated by Tempo.
        namespace = "traces.spanmetrics"
      
        // Each extra dimension (metrics label) to be added to the generated metrics from matching span attributes. These
        // need to be defined with a name and optionally a default value (in the following cases, we do not want a default
        // value if the span attribute is not present).
        dimension {
          name = "http.method"
        }
      
        dimension {
          name = "http.target"
        }
      
        dimension {
          name = "http.status_code"
        }
      
        dimensions_cache_size = 333

        aggregation_temporality = "DELTA"
      
        dimension {
          name = "service.version"
        }
      
        // A histogram block must be present, either explicitly defining bucket values or via an exponential block.
        // We do the latter here.
        histogram {
          unit = "s"
          explicit {
            buckets = ["333ms", "777s", "999h"]
          }
        }

        // The exemplar block is added to ensure we generate exemplars for traces on relevant metric values.
        exemplars {
          enabled = true
        }
      
        // Generated metrics data is in OTLP format. We send this data to the OpenTelemetry Prometheus exporter to ensure
        // it gets transformed into Prometheus format data.
        output {
          metrics = [otelcol.exporter.prometheus.tracemetrics.input]
        }
      }
